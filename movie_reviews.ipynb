{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie-reviews.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/IZhA24nvhtEosfqNn1AI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndevar132/demo-repo/blob/master/movie_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqKSbwX840dx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "202e4d5c-3cd9-4dd8-b5e7-4e6a509bb2d2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "data = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=88000)\n",
        "\n",
        "\n",
        "\n",
        "word_index = data.get_word_index()\n",
        "word_index = {k: (v+3) for k, v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
        "\n",
        "\n",
        "\n",
        "def decode_review(text):\n",
        "  return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
        "\n",
        "# model down here\n",
        "'''\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(88000, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "x_val = train_data[:10000]\n",
        "x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "y_train = train_labels[10000:]\n",
        "\n",
        "fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)\n",
        "\n",
        "model.save(\"model.h5\")\n",
        "'''\n",
        "\n",
        "def review_encode(s):\n",
        "  encoded = [1]\n",
        "\n",
        "  for word in s:\n",
        "    if word.lower() in word_index:\n",
        "      encoded.append(word_index[word.lower()])\n",
        "    else:\n",
        "      encoded.append(2)\n",
        "\n",
        "  return encoded\n",
        "\n",
        "model = keras.models.load_model(\"model.h5\")\n",
        "\n",
        "\n",
        "filename = \"test.txt\"\n",
        "with open(filename, encoding=\"utf-8\") as f:\n",
        "  for line in f.readlines():\n",
        "    nline = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace(\"\\\"\", \"\").strip().split(\" \")\n",
        "    encode = review_encode(nline)\n",
        "    encode = keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
        "    predict = model.predict(encode)\n",
        "    print(line)\n",
        "    print(encode)\n",
        "    print(predict[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "test_review = test_data[0]\n",
        "predict = model.predict([test_review])\n",
        "print(\"Review: \")\n",
        "print(decode_review(test_review))\n",
        "print(\"Prediction: \" + str(predict[0]))\n",
        "print(\"Actual: \" + str(test_labels[0]))\n",
        "'''\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I find it hard to believe that kid's movies these days will ever be called classics in years to come (excluding Pixar movies). In my mind, this is the last classic hand drawn film, and it upsets me that I have to wait for another five years for it to come out on DVD. This film deals with great issues and involves a huge conflict for the main character, something that recent kid/family films lack. It is funny and lighthearted when it should be, and heartfelt and serious when it needs it. I believe that everybody should see this movie, regardless of your age. It may just be the last good movie that Disney will ever do without the help of Pixar.\n",
            "\n",
            "[[    1    13   169    12   254     8   264    15  5502   102   134   504\n",
            "     80   126    30   446  2239    11   153     8   216 16175  6568   102\n",
            "     11    61   330    14     9     4   236   356   508  1309    22     5\n",
            "     12 14808    72    15    13    28     8   858    18   160   677   153\n",
            "     18    12     8   216    46    23   288    14    22  2033    19    87\n",
            "   1341     5  2290     6   666  1944    18     4   293   109   142    15\n",
            "   1136     2   108   583    12     9   163     5  8373    54    12   144\n",
            "     30     5  5348     5   622    54    12   738    12    13   264    15\n",
            "   1462   144    67    14    20  3563     7   129   559    12   203    43\n",
            "     30     4   236    52    20    15   910    80   126    81   209     4\n",
            "    339     7  6568     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]]\n",
            "[0.99233997]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntest_review = test_data[0]\\npredict = model.predict([test_review])\\nprint(\"Review: \")\\nprint(decode_review(test_review))\\nprint(\"Prediction: \" + str(predict[0]))\\nprint(\"Actual: \" + str(test_labels[0]))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}